paths:
  '/responses/{response_id}':
    get:
      tags:
        - Responses
      summary: "Retrieves a model response with the given ID.\n"
      operationId: getResponse
      parameters:
        - name: response_id
          in: path
          description: The ID of the response to retrieve.
          required: true
          schema:
            type: string
            example: resp_677efb5139a88190b512bc3fef8e535d
        - name: include
          in: query
          description: "Additional fields to include in the response. See the `include`\nparameter for Response creation above for more information.\n"
          schema:
            type: array
            items:
              $ref: '#/components/schemas/Includable'
        - name: stream
          in: query
          description: "If set to true, the model response data will be streamed to the client\nas it is generated using [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format).\nSee the [Streaming section below](/docs/api-reference/responses-streaming)\nfor more information.\n"
          schema:
            type: boolean
        - name: starting_after
          in: query
          description: "The sequence number of the event after which to start streaming.\n"
          schema:
            type: integer
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Response'
      x-oaiMeta:
        name: Get a model response
        group: responses
        returns: "The [Response](/docs/api-reference/responses/object) object matching the\nspecified ID.\n"
        examples:
          response: "{\n  \"id\": \"resp_67cb71b351908190a308f3859487620d06981a8637e6bc44\",\n  \"object\": \"response\",\n  \"created_at\": 1741386163,\n  \"status\": \"completed\",\n  \"error\": null,\n  \"incomplete_details\": null,\n  \"instructions\": null,\n  \"max_output_tokens\": null,\n  \"model\": \"gpt-4o-2024-08-06\",\n  \"output\": [\n    {\n      \"type\": \"message\",\n      \"id\": \"msg_67cb71b3c2b0819084d481baaaf148f206981a8637e6bc44\",\n      \"status\": \"completed\",\n      \"role\": \"assistant\",\n      \"content\": [\n        {\n          \"type\": \"output_text\",\n          \"text\": \"Silent circuits hum,  \\nThoughts emerge in data streamsâ€”  \\nDigital dawn breaks.\",\n          \"annotations\": []\n        }\n      ]\n    }\n  ],\n  \"parallel_tool_calls\": true,\n  \"previous_response_id\": null,\n  \"reasoning\": {\n    \"effort\": null,\n    \"summary\": null\n  },\n  \"store\": true,\n  \"temperature\": 1.0,\n  \"text\": {\n    \"format\": {\n      \"type\": \"text\"\n    }\n  },\n  \"tool_choice\": \"auto\",\n  \"tools\": [],\n  \"top_p\": 1.0,\n  \"truncation\": \"disabled\",\n  \"usage\": {\n    \"input_tokens\": 32,\n    \"input_tokens_details\": {\n      \"cached_tokens\": 0\n    },\n    \"output_tokens\": 18,\n    \"output_tokens_details\": {\n      \"reasoning_tokens\": 0\n    },\n    \"total_tokens\": 50\n  },\n  \"user\": null,\n  \"metadata\": {}\n}\n"
          request:
            curl: "curl https://api.openai.com/v1/responses/resp_123 \\\n    -H \"Content-Type: application/json\" \\\n    -H \"Authorization: Bearer $OPENAI_API_KEY\"\n"
            javascript: "import OpenAI from \"openai\";\nconst client = new OpenAI();\n\nconst response = await client.responses.retrieve(\"resp_123\");\nconsole.log(response);\n"
            python: "import os\nfrom openai import OpenAI\n\nclient = OpenAI(\n    api_key=os.environ.get(\"OPENAI_API_KEY\"),  # This is the default and can be omitted\n)\nresponse = client.responses.retrieve(\n    response_id=\"resp_677efb5139a88190b512bc3fef8e535d\",\n)\nprint(response.id)"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: process.env['OPENAI_API_KEY'], // This is the default and can be omitted\n});\n\nconst response = await client.responses.retrieve('resp_677efb5139a88190b512bc3fef8e535d');\n\nconsole.log(response.id);"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n  \"github.com/openai/openai-go/responses\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"), // defaults to os.LookupEnv(\"OPENAI_API_KEY\")\n  )\n  response, err := client.Responses.Get(\n    context.TODO(),\n    \"resp_677efb5139a88190b512bc3fef8e535d\",\n    responses.ResponseGetParams{\n\n    },\n  )\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", response.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.responses.Response;\nimport com.openai.models.responses.ResponseRetrieveParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        // Configures using the `OPENAI_API_KEY`, `OPENAI_ORG_ID`, `OPENAI_PROJECT_ID`, `OPENAI_WEBHOOK_SECRET` and `OPENAI_BASE_URL` environment variables\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        Response response = client.responses().retrieve(\"resp_677efb5139a88190b512bc3fef8e535d\");\n    }\n}"
            kotlin: "package com.openai.example\n\nimport com.openai.client.OpenAIClient\nimport com.openai.client.okhttp.OpenAIOkHttpClient\nimport com.openai.models.responses.Response\nimport com.openai.models.responses.ResponseRetrieveParams\n\nfun main() {\n    // Configures using the `OPENAI_API_KEY`, `OPENAI_ORG_ID`, `OPENAI_PROJECT_ID`, `OPENAI_WEBHOOK_SECRET` and `OPENAI_BASE_URL` environment variables\n    val client: OpenAIClient = OpenAIOkHttpClient.fromEnv()\n\n    val response: Response = client.responses().retrieve(\"resp_677efb5139a88190b512bc3fef8e535d\")\n}"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(\n  api_key: ENV[\"OPENAI_API_KEY\"] # This is the default and can be omitted\n)\n\nresponse = openai.responses.retrieve(\"resp_677efb5139a88190b512bc3fef8e535d\")\n\nputs(response)"
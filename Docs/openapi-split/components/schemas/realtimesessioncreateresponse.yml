components:
  schemas:
    RealtimeSessionCreateResponse:
      required:
        - client_secret
      type: object
      properties:
        client_secret:
          required:
            - value
            - expires_at
          type: object
          properties:
            value:
              type: string
              description: "Ephemeral key usable in client environments to authenticate connections\nto the Realtime API. Use this in client-side environments rather than\na standard API token, which should only be used server-side.\n"
            expires_at:
              type: integer
              description: "Timestamp for when the token expires. Currently, all tokens expire\nafter one minute.\n"
          description: Ephemeral key returned by the API.
        modalities:
          items:
            enum:
              - text
              - audio
            type: string
          description: "The set of modalities the model can respond with. To disable audio,\nset this to [\"text\"].\n"
        instructions:
          type: string
          description: "The default system instructions (i.e. system message) prepended to model \ncalls. This field allows the client to guide the model on desired \nresponses. The model can be instructed on response content and format, \n(e.g. \"be extremely succinct\", \"act friendly\", \"here are examples of good \nresponses\") and on audio behavior (e.g. \"talk quickly\", \"inject emotion \ninto your voice\", \"laugh frequently\"). The instructions are not guaranteed \nto be followed by the model, but they provide guidance to the model on the \ndesired behavior.\n\nNote that the server sets default instructions which will be used if this \nfield is not set and are visible in the `session.created` event at the \nstart of the session.\n"
        voice:
          $ref: '#/components/schemas/VoiceIdsShared'
        input_audio_format:
          type: string
          description: "The format of input audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`.\n"
        output_audio_format:
          type: string
          description: "The format of output audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`.\n"
        input_audio_transcription:
          type: object
          properties:
            model:
              type: string
              description: "The model to use for transcription.\n"
          description: "Configuration for input audio transcription, defaults to off and can be \nset to `null` to turn off once on. Input audio transcription is not native \nto the model, since the model consumes audio directly. Transcription runs\nasynchronously and should be treated as rough guidance\nrather than the representation understood by the model.\n"
        speed:
          maximum: 1.5
          minimum: 0.25
          type: number
          description: "The speed of the model's spoken response. 1.0 is the default speed. 0.25 is\nthe minimum speed. 1.5 is the maximum speed. This value can only be changed\nin between model turns, not while a response is in progress.\n"
          default: 1
        tracing:
          title: Tracing Configuration
          oneOf:
            - enum:
                - auto
              type: string
              description: "Default tracing mode for the session.\n"
              default: auto
              x-stainless-const: true
            - title: Tracing Configuration
              type: object
              properties:
                workflow_name:
                  type: string
                  description: "The name of the workflow to attach to this trace. This is used to \nname the trace in the traces dashboard.\n"
                group_id:
                  type: string
                  description: "The group id to attach to this trace to enable filtering and \ngrouping in the traces dashboard.\n"
                metadata:
                  type: object
                  description: "The arbitrary metadata to attach to this trace to enable \nfiltering in the traces dashboard.\n"
              description: "Granular configuration for tracing.\n"
          description: "Configuration options for tracing. Set to null to disable tracing. Once \ntracing is enabled for a session, the configuration cannot be modified.\n\n`auto` will create a trace for the session with default values for the \nworkflow name, group id, and metadata.\n"
        turn_detection:
          type: object
          properties:
            type:
              type: string
              description: "Type of turn detection, only `server_vad` is currently supported.\n"
            threshold:
              type: number
              description: "Activation threshold for VAD (0.0 to 1.0), this defaults to 0.5. A \nhigher threshold will require louder audio to activate the model, and \nthus might perform better in noisy environments.\n"
            prefix_padding_ms:
              type: integer
              description: "Amount of audio to include before the VAD detected speech (in \nmilliseconds). Defaults to 300ms.\n"
            silence_duration_ms:
              type: integer
              description: "Duration of silence to detect speech stop (in milliseconds). Defaults \nto 500ms. With shorter values the model will respond more quickly, \nbut may jump in on short pauses from the user.\n"
          description: "Configuration for turn detection. Can be set to `null` to turn off. Server \nVAD means that the model will detect the start and end of speech based on \naudio volume and respond at the end of user speech.\n"
        tools:
          type: array
          items:
            type: object
            properties:
              type:
                enum:
                  - function
                type: string
                description: 'The type of the tool, i.e. `function`.'
                x-stainless-const: true
              name:
                type: string
                description: The name of the function.
              description:
                type: string
                description: "The description of the function, including guidance on when and how \nto call it, and guidance about what to tell the user when calling \n(if anything).\n"
              parameters:
                type: object
                description: Parameters of the function in JSON Schema.
          description: Tools (functions) available to the model.
        tool_choice:
          type: string
          description: "How the model chooses tools. Options are `auto`, `none`, `required`, or \nspecify a function.\n"
        temperature:
          type: number
          description: "Sampling temperature for the model, limited to [0.6, 1.2]. Defaults to 0.8.\n"
        max_response_output_tokens:
          oneOf:
            - type: integer
            - enum:
                - inf
              type: string
              x-stainless-const: true
          description: "Maximum number of output tokens for a single assistant response,\ninclusive of tool calls. Provide an integer between 1 and 4096 to\nlimit output tokens, or `inf` for the maximum available tokens for a\ngiven model. Defaults to `inf`.\n"
      description: "A new Realtime session configuration, with an ephermeral key. Default TTL\nfor keys is one minute.\n"
      x-oaiMeta:
        name: The session object
        group: realtime
        example: "{\n  \"id\": \"sess_001\",\n  \"object\": \"realtime.session\",\n  \"model\": \"gpt-4o-realtime-preview\",\n  \"modalities\": [\"audio\", \"text\"],\n  \"instructions\": \"You are a friendly assistant.\",\n  \"voice\": \"alloy\",\n  \"input_audio_format\": \"pcm16\",\n  \"output_audio_format\": \"pcm16\",\n  \"input_audio_transcription\": {\n      \"model\": \"whisper-1\"\n  },\n  \"turn_detection\": null,\n  \"tools\": [],\n  \"tool_choice\": \"none\",\n  \"temperature\": 0.7,\n  \"speed\": 1.1,\n  \"tracing\": \"auto\",\n  \"max_response_output_tokens\": 200,\n  \"client_secret\": {\n    \"value\": \"ek_abc123\", \n    \"expires_at\": 1234567890\n  }\n}\n"
components:
  schemas:
    FineTuneDPOHyperparameters:
      type: object
      properties:
        beta:
          anyOf:
            - enum:
                - auto
              type: string
              x-stainless-const: true
            - maximum: 2
              minimum: True
              exclusiveMinimum: true
              type: number
          description: "The beta value for the DPO method. A higher beta value will increase the weight of the penalty between the policy and reference model.\n"
        batch_size:
          anyOf:
            - enum:
                - auto
              type: string
              x-stainless-const: true
            - maximum: 256
              minimum: 1
              type: integer
          description: "Number of examples in each batch. A larger batch size means that model parameters are updated less frequently, but with lower variance.\n"
          default: auto
        learning_rate_multiplier:
          anyOf:
            - enum:
                - auto
              type: string
              x-stainless-const: true
            - minimum: True
              exclusiveMinimum: true
              type: number
          description: "Scaling factor for the learning rate. A smaller learning rate may be useful to avoid overfitting.\n"
        n_epochs:
          anyOf:
            - enum:
                - auto
              type: string
              x-stainless-const: true
            - maximum: 50
              minimum: 1
              type: integer
          description: "The number of epochs to train the model for. An epoch refers to one full cycle through the training dataset.\n"
          default: auto
      description: The hyperparameters used for the DPO fine-tuning job.
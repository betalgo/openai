components:
  schemas:
    RealtimeServerEventConversationItemInputAudioTranscriptionCompleted:
      required:
        - event_id
        - type
        - item_id
        - content_index
        - transcript
        - usage
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
        type:
          enum:
            - conversation.item.input_audio_transcription.completed
          type: string
          description: "The event type, must be\n`conversation.item.input_audio_transcription.completed`.\n"
          x-stainless-const: true
        item_id:
          type: string
          description: The ID of the item containing the audio that is being transcribed.
        content_index:
          type: integer
          description: The index of the content part containing the audio.
        transcript:
          type: string
          description: The transcribed text.
        logprobs:
          anyOf:
            - type: array
              items:
                $ref: '#/components/schemas/LogProbProperties'
              description: The log probabilities of the transcription.
            - nullable: true
        usage:
          type: object
          anyOf:
            - $ref: '#/components/schemas/TranscriptTextUsageTokens'
            - $ref: '#/components/schemas/TranscriptTextUsageDuration'
          description: 'Usage statistics for the transcription, this is billed according to the ASR model''s pricing rather than the realtime model''s pricing.'
      description: "This event is the output of audio transcription for user audio written to the\nuser audio buffer. Transcription begins when the input audio buffer is\ncommitted by the client or server (when VAD is enabled). Transcription runs\nasynchronously with Response creation, so this event may come before or after\nthe Response events.\n\nRealtime API models accept audio natively, and thus input transcription is a\nseparate process run on a separate ASR (Automatic Speech Recognition) model.\nThe transcript may diverge somewhat from the model's interpretation, and\nshould be treated as a rough guide.\n"
      x-oaiMeta:
        name: conversation.item.input_audio_transcription.completed
        group: realtime
        example: "{\n  \"type\": \"conversation.item.input_audio_transcription.completed\",\n  \"event_id\": \"event_CCXGRvtUVrax5SJAnNOWZ\",\n  \"item_id\": \"item_CCXGQ4e1ht4cOraEYcuR2\",\n  \"content_index\": 0,\n  \"transcript\": \"Hey, can you hear me?\",\n  \"usage\": {\n    \"type\": \"tokens\",\n    \"total_tokens\": 22,\n    \"input_tokens\": 13,\n    \"input_token_details\": {\n      \"text_tokens\": 0,\n      \"audio_tokens\": 13\n    },\n    \"output_tokens\": 9\n  }\n}\n"
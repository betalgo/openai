components:
  schemas:
    ModelResponseProperties:
      type: object
      properties:
        metadata:
          $ref: '#/components/schemas/Metadata'
        top_logprobs:
          anyOf:
            - maximum: 20
              minimum: 0
              type: integer
              description: "An integer between 0 and 20 specifying the number of most likely tokens to\nreturn at each token position, each with an associated log probability.\n"
            - nullable: true
        temperature:
          anyOf:
            - maximum: 2
              minimum: 0
              type: number
              description: "What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\nWe generally recommend altering this or `top_p` but not both.\n"
              default: 1
              example: 1
            - nullable: true
        top_p:
          anyOf:
            - maximum: 1
              minimum: 0
              type: number
              description: "An alternative to sampling with temperature, called nucleus sampling,\nwhere the model considers the results of the tokens with top_p probability\nmass. So 0.1 means only the tokens comprising the top 10% probability mass\nare considered.\n\nWe generally recommend altering this or `temperature` but not both.\n"
              default: 1
              example: 1
            - nullable: true
        user:
          type: string
          description: "This field is being replaced by `safety_identifier` and `prompt_cache_key`. Use `prompt_cache_key` instead to maintain caching optimizations.\nA stable identifier for your end-users.\nUsed to boost cache hit rates by better bucketing similar requests and  to help OpenAI detect and prevent abuse. [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#safety-identifiers).\n"
          example: user-1234
          deprecated: true
        safety_identifier:
          type: string
          description: "A stable identifier used to help detect users of your application that may be violating OpenAI's usage policies.\nThe IDs should be a string that uniquely identifies each user. We recommend hashing their username or email address, in order to avoid sending us any identifying information. [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#safety-identifiers).\n"
          example: safety-identifier-1234
        prompt_cache_key:
          type: string
          description: "Used by OpenAI to cache responses for similar requests to optimize your cache hit rates. Replaces the `user` field. [Learn more](https://platform.openai.com/docs/guides/prompt-caching).\n"
          example: prompt-cache-key-1234
        service_tier:
          $ref: '#/components/schemas/ServiceTier'
        prompt_cache_retention:
          anyOf:
            - enum:
                - in-memory
                - 24h
              type: string
              description: "The retention policy for the prompt cache. Set to `24h` to enable extended prompt caching, which keeps cached prefixes active for longer, up to a maximum of 24 hours. [Learn more](https://platform.openai.com/docs/guides/prompt-caching#prompt-cache-retention).\n"
            - nullable: true
components:
  schemas:
    CreateResponse:
      allOf:
        - $ref: '#/components/schemas/CreateModelResponseProperties'
        - $ref: '#/components/schemas/ResponseProperties'
        - type: object
          properties:
            input:
              $ref: '#/components/schemas/InputParam'
            include:
              anyOf:
                - type: array
                  items:
                    $ref: '#/components/schemas/IncludeEnum'
                  description: "Specify additional output data to include in the model response. Currently supported values are:\n- `web_search_call.action.sources`: Include the sources of the web search tool call.\n- `code_interpreter_call.outputs`: Includes the outputs of python code execution in code interpreter tool call items.\n- `computer_call_output.output.image_url`: Include image urls from the computer call output.\n- `file_search_call.results`: Include the search results of the file search tool call.\n- `message.input_image.image_url`: Include image urls from the input message.\n- `message.output_text.logprobs`: Include logprobs with assistant messages.\n- `reasoning.encrypted_content`: Includes an encrypted version of reasoning tokens in reasoning item outputs. This enables reasoning items to be used in multi-turn conversations when using the Responses API statelessly (like when the `store` parameter is set to `false`, or when an organization is enrolled in the zero data retention program)."
                - nullable: true
            parallel_tool_calls:
              anyOf:
                - type: boolean
                  description: "Whether to allow the model to run tool calls in parallel.\n"
                  default: true
                - nullable: true
            store:
              anyOf:
                - type: boolean
                  description: "Whether to store the generated model response for later retrieval via\nAPI.\n"
                  default: true
                - nullable: true
            instructions:
              anyOf:
                - type: string
                  description: "A system (or developer) message inserted into the model's context.\n\nWhen using along with `previous_response_id`, the instructions from a previous\nresponse will not be carried over to the next response. This makes it simple\nto swap out system (or developer) messages in new responses.\n"
                - nullable: true
            stream:
              anyOf:
                - type: boolean
                  description: "If set to true, the model response data will be streamed to the client\nas it is generated using [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format).\nSee the [Streaming section below](https://platform.openai.com/docs/api-reference/responses-streaming)\nfor more information.\n"
                  default: false
                - nullable: true
            stream_options:
              $ref: '#/components/schemas/ResponseStreamOptions'
            conversation:
              anyOf:
                - $ref: '#/components/schemas/ConversationParam'
                - nullable: true
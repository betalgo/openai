components:
  schemas:
    CreateChatCompletionRequest:
      allOf:
        - $ref: '#/components/schemas/CreateModelResponseProperties'
        - required:
            - model
            - messages
          type: object
          properties:
            messages:
              minItems: 1
              type: array
              items:
                $ref: '#/components/schemas/ChatCompletionRequestMessage'
              description: "A list of messages comprising the conversation so far. Depending on the\n[model](/docs/models) you use, different message types (modalities) are\nsupported, like [text](/docs/guides/text-generation),\n[images](/docs/guides/vision), and [audio](/docs/guides/audio).\n"
            model:
              $ref: '#/components/schemas/ModelIdsShared'
            modalities:
              $ref: '#/components/schemas/ResponseModalities'
            reasoning_effort:
              $ref: '#/components/schemas/ReasoningEffort'
            max_completion_tokens:
              type: integer
              description: "An upper bound for the number of tokens that can be generated for a completion, including visible output tokens and [reasoning tokens](/docs/guides/reasoning).\n"
              nullable: true
            frequency_penalty:
              maximum: 2
              minimum: -2
              type: number
              description: "Number between -2.0 and 2.0. Positive values penalize new tokens based on\ntheir existing frequency in the text so far, decreasing the model's\nlikelihood to repeat the same line verbatim.\n"
              default: 0
              nullable: true
            presence_penalty:
              maximum: 2
              minimum: -2
              type: number
              description: "Number between -2.0 and 2.0. Positive values penalize new tokens based on\nwhether they appear in the text so far, increasing the model's likelihood\nto talk about new topics.\n"
              default: 0
              nullable: true
            web_search_options:
              title: Web search
              type: object
              properties:
                user_location:
                  required:
                    - type
                    - approximate
                  type: object
                  properties:
                    type:
                      enum:
                        - approximate
                      type: string
                      description: "The type of location approximation. Always `approximate`.\n"
                      x-stainless-const: true
                    approximate:
                      $ref: '#/components/schemas/WebSearchLocation'
                  description: "Approximate location parameters for the search.\n"
                  nullable: true
                search_context_size:
                  $ref: '#/components/schemas/WebSearchContextSize'
              description: "This tool searches the web for relevant results to use in a response.\nLearn more about the [web search tool](/docs/guides/tools-web-search?api-mode=chat).\n"
            top_logprobs:
              maximum: 20
              minimum: 0
              type: integer
              description: "An integer between 0 and 20 specifying the number of most likely tokens to\nreturn at each token position, each with an associated log probability.\n`logprobs` must be set to `true` if this parameter is used.\n"
              nullable: true
            response_format:
              oneOf:
                - $ref: '#/components/schemas/ResponseFormatText'
                - $ref: '#/components/schemas/ResponseFormatJsonSchema'
                - $ref: '#/components/schemas/ResponseFormatJsonObject'
              description: "An object specifying the format that the model must output.\n\nSetting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables\nStructured Outputs which ensures the model will match your supplied JSON\nschema. Learn more in the [Structured Outputs\nguide](/docs/guides/structured-outputs).\n\nSetting to `{ \"type\": \"json_object\" }` enables the older JSON mode, which\nensures the message the model generates is valid JSON. Using `json_schema`\nis preferred for models that support it.\n"
            audio:
              required:
                - voice
                - format
              type: object
              properties:
                voice:
                  $ref: '#/components/schemas/VoiceIdsShared'
                format:
                  enum:
                    - wav
                    - aac
                    - mp3
                    - flac
                    - opus
                    - pcm16
                  type: string
                  description: "Specifies the output audio format. Must be one of `wav`, `mp3`, `flac`,\n`opus`, or `pcm16`.\n"
              description: "Parameters for audio output. Required when audio output is requested with\n`modalities: [\"audio\"]`. [Learn more](/docs/guides/audio).\n"
              nullable: true
            store:
              type: boolean
              description: "Whether or not to store the output of this chat completion request for \nuse in our [model distillation](/docs/guides/distillation) or\n[evals](/docs/guides/evals) products. \n\nSupports text and image inputs. Note: image inputs over 10MB will be dropped.\n"
              default: false
              nullable: true
            stream:
              type: boolean
              description: "If set to true, the model response data will be streamed to the client\nas it is generated using [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format).\nSee the [Streaming section below](/docs/api-reference/chat/streaming)\nfor more information, along with the [streaming responses](/docs/guides/streaming-responses)\nguide for more information on how to handle the streaming events.\n"
              default: false
              nullable: true
            stop:
              $ref: '#/components/schemas/StopConfiguration'
            logit_bias:
              type: object
              additionalProperties:
                type: integer
              description: "Modify the likelihood of specified tokens appearing in the completion.\n\nAccepts a JSON object that maps tokens (specified by their token ID in the\ntokenizer) to an associated bias value from -100 to 100. Mathematically,\nthe bias is added to the logits generated by the model prior to sampling.\nThe exact effect will vary per model, but values between -1 and 1 should\ndecrease or increase likelihood of selection; values like -100 or 100\nshould result in a ban or exclusive selection of the relevant token.\n"
              default: null
              nullable: true
              x-oaiTypeLabel: map
            logprobs:
              type: boolean
              description: "Whether to return log probabilities of the output tokens or not. If true,\nreturns the log probabilities of each output token returned in the\n`content` of `message`.\n"
              default: false
              nullable: true
            max_tokens:
              type: integer
              description: "The maximum number of [tokens](/tokenizer) that can be generated in the\nchat completion. This value can be used to control\n[costs](https://openai.com/api/pricing/) for text generated via API.\n\nThis value is now deprecated in favor of `max_completion_tokens`, and is\nnot compatible with [o-series models](/docs/guides/reasoning).\n"
              nullable: true
              deprecated: true
            n:
              maximum: 128
              minimum: 1
              type: integer
              description: How many chat completion choices to generate for each input message. Note that you will be charged based on the number of generated tokens across all of the choices. Keep `n` as `1` to minimize costs.
              default: 1
              nullable: true
              example: 1
            prediction:
              oneOf:
                - $ref: '#/components/schemas/PredictionContent'
              description: "Configuration for a [Predicted Output](/docs/guides/predicted-outputs),\nwhich can greatly improve response times when large parts of the model\nresponse are known ahead of time. This is most common when you are\nregenerating a file with only minor changes to most of the content.\n"
              nullable: true
            seed:
              maximum: 9223372036854776000
              minimum: -9223372036854776000
              type: integer
              description: "This feature is in Beta.\nIf specified, our system will make a best effort to sample deterministically, such that repeated requests with the same `seed` and parameters should return the same result.\nDeterminism is not guaranteed, and you should refer to the `system_fingerprint` response parameter to monitor changes in the backend.\n"
              nullable: true
              x-oaiMeta:
                beta: true
            stream_options:
              $ref: '#/components/schemas/ChatCompletionStreamOptions'
            tools:
              type: array
              items:
                $ref: '#/components/schemas/ChatCompletionTool'
              description: "A list of tools the model may call. Currently, only functions are supported as a tool. Use this to provide a list of functions the model may generate JSON inputs for. A max of 128 functions are supported.\n"
            tool_choice:
              $ref: '#/components/schemas/ChatCompletionToolChoiceOption'
            parallel_tool_calls:
              $ref: '#/components/schemas/ParallelToolCalls'
            function_call:
              oneOf:
                - enum:
                    - none
                    - auto
                  type: string
                  description: "`none` means the model will not call a function and instead generates a message. `auto` means the model can pick between generating a message or calling a function.\n"
                - $ref: '#/components/schemas/ChatCompletionFunctionCallOption'
              description: "Deprecated in favor of `tool_choice`.\n\nControls which (if any) function is called by the model.\n\n`none` means the model will not call a function and instead generates a\nmessage.\n\n`auto` means the model can pick between generating a message or calling a\nfunction.\n\nSpecifying a particular function via `{\"name\": \"my_function\"}` forces the\nmodel to call that function.\n\n`none` is the default when no functions are present. `auto` is the default\nif functions are present.\n"
              deprecated: true
            functions:
              maxItems: 128
              minItems: 1
              type: array
              items:
                $ref: '#/components/schemas/ChatCompletionFunctions'
              description: "Deprecated in favor of `tools`.\n\nA list of functions the model may generate JSON inputs for.\n"
              deprecated: true